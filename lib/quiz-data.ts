import type { QuizQuestion } from "@/types"

export const QUIZ_QUESTIONS: QuizQuestion[] = [
  {
    id: "q001",
    topic: "arrays",
    difficulty: "easy",
    question: "What is the time complexity of accessing an element in an array by index?",
    options: ["O(1)", "O(log n)", "O(n)", "O(n²)"],
    correctAnswer: "O(1)",
    explanation: "Array elements can be accessed directly using their index in constant time.",
    tags: ["time-complexity", "arrays", "fundamentals"],
  },
  {
    id: "q002",
    topic: "arrays",
    difficulty: "medium",
    question: "Which approach is most efficient for finding two numbers in a sorted array that sum to a target?",
    options: ["Brute force O(n²)", "Two pointers O(n)", "Binary search O(n log n)", "Hash map O(n)"],
    correctAnswer: "Two pointers O(n)",
    explanation: "For sorted arrays, two pointers technique is optimal as it leverages the sorted property.",
    tags: ["two-pointers", "arrays", "optimization"],
  },
  {
    id: "q003",
    topic: "linked-lists",
    difficulty: "easy",
    question: "What is the time complexity of inserting an element at the beginning of a linked list?",
    options: ["O(1)", "O(log n)", "O(n)", "O(n²)"],
    correctAnswer: "O(1)",
    explanation: "Inserting at the head of a linked list only requires updating a few pointers.",
    tags: ["linked-lists", "insertion", "time-complexity"],
  },
  {
    id: "q004",
    topic: "linked-lists",
    difficulty: "medium",
    question: "How would you detect a cycle in a linked list most efficiently?",
    options: [
      "Use a hash set",
      "Floyd's cycle detection (tortoise and hare)",
      "Mark visited nodes",
      "All approaches are equally efficient",
    ],
    correctAnswer: "Floyd's cycle detection (tortoise and hare)",
    explanation: "Floyd's algorithm uses O(1) space compared to O(n) for hash set approach.",
    tags: ["linked-lists", "cycle-detection", "algorithms"],
  },
  {
    id: "q005",
    topic: "trees",
    difficulty: "easy",
    question: "In a binary search tree, what is the time complexity of searching for an element in the average case?",
    options: ["O(1)", "O(log n)", "O(n)", "O(n log n)"],
    correctAnswer: "O(log n)",
    explanation: "BST search eliminates half the tree at each step in the average case.",
    tags: ["trees", "binary-search-tree", "search"],
  },
  {
    id: "q006",
    topic: "trees",
    difficulty: "medium",
    question: "Which traversal method would you use to copy a binary tree?",
    options: ["Inorder", "Preorder", "Postorder", "Level order"],
    correctAnswer: "Preorder",
    explanation: "Preorder (root, left, right) naturally follows the construction pattern for copying trees.",
    tags: ["trees", "traversal", "tree-construction"],
  },
  {
    id: "q007",
    topic: "sorting",
    difficulty: "easy",
    question: "Which sorting algorithm has the best average-case time complexity?",
    options: ["Bubble Sort O(n²)", "Merge Sort O(n log n)", "Selection Sort O(n²)", "Insertion Sort O(n²)"],
    correctAnswer: "Merge Sort O(n log n)",
    explanation: "Merge sort consistently performs at O(n log n) in all cases.",
    tags: ["sorting", "time-complexity", "algorithms"],
  },
  {
    id: "q008",
    topic: "sorting",
    difficulty: "medium",
    question: "When would you choose Quick Sort over Merge Sort?",
    options: [
      "When you need stable sorting",
      "When you want to minimize space complexity",
      "When you need guaranteed O(n log n)",
      "When working with linked lists",
    ],
    correctAnswer: "When you want to minimize space complexity",
    explanation: "Quick sort is in-place (O(log n) space) while merge sort requires O(n) additional space.",
    tags: ["sorting", "space-complexity", "trade-offs"],
  },
  {
    id: "q009",
    topic: "dynamic-programming",
    difficulty: "medium",
    question: "What is the key principle behind dynamic programming?",
    options: [
      "Divide and conquer",
      "Optimal substructure and overlapping subproblems",
      "Greedy choice",
      "Backtracking",
    ],
    correctAnswer: "Optimal substructure and overlapping subproblems",
    explanation: "DP solves problems by breaking them into overlapping subproblems with optimal substructure.",
    tags: ["dynamic-programming", "principles", "optimization"],
  },
  {
    id: "q010",
    topic: "dynamic-programming",
    difficulty: "hard",
    question: "In the 0/1 Knapsack problem, what does the DP table dp[i][w] represent?",
    options: [
      "Weight of item i",
      "Value of item i",
      "Maximum value using first i items with weight limit w",
      "Number of items with weight w",
    ],
    correctAnswer: "Maximum value using first i items with weight limit w",
    explanation: "Each cell represents the optimal solution for a subproblem with specific constraints.",
    tags: ["dynamic-programming", "knapsack", "problem-solving"],
  },
  {
    id: "q011",
    topic: "recursion",
    difficulty: "easy",
    question: "What is essential for every recursive function to avoid infinite recursion?",
    options: ["A loop", "A base case", "Multiple parameters", "Return statement"],
    correctAnswer: "A base case",
    explanation: "Base cases provide termination conditions for recursive calls.",
    tags: ["recursion", "base-case", "fundamentals"],
  },
  {
    id: "q012",
    topic: "recursion",
    difficulty: "medium",
    question: "What is the time complexity of the naive recursive Fibonacci implementation?",
    options: ["O(n)", "O(log n)", "O(2^n)", "O(n²)"],
    correctAnswer: "O(2^n)",
    explanation: "Each call branches into two more calls, creating exponential growth.",
    tags: ["recursion", "fibonacci", "time-complexity"],
  },
  {
    id: "q013",
    topic: "graphs",
    difficulty: "medium",
    question: "Which algorithm would you use to find the shortest path in an unweighted graph?",
    options: ["Dijkstra's algorithm", "Breadth-First Search (BFS)", "Depth-First Search (DFS)", "Floyd-Warshall"],
    correctAnswer: "Breadth-First Search (BFS)",
    explanation: "BFS naturally finds shortest paths in unweighted graphs by exploring level by level.",
    tags: ["graphs", "shortest-path", "bfs"],
  },
  {
    id: "q014",
    topic: "graphs",
    difficulty: "hard",
    question: "What is the time complexity of Dijkstra's algorithm using a binary heap?",
    options: ["O(V + E)", "O(V log V)", "O((V + E) log V)", "O(V²)"],
    correctAnswer: "O((V + E) log V)",
    explanation: "Each vertex is extracted once (V log V) and each edge is relaxed once (E log V).",
    tags: ["graphs", "dijkstra", "time-complexity"],
  },
  {
    id: "q015",
    topic: "hash-tables",
    difficulty: "easy",
    question: "What is the average time complexity for insertion in a hash table?",
    options: ["O(1)", "O(log n)", "O(n)", "O(n²)"],
    correctAnswer: "O(1)",
    explanation: "Hash tables provide constant time insertion on average with good hash functions.",
    tags: ["hash-tables", "insertion", "time-complexity"],
  },
  {
    id: "q016",
    topic: "hash-tables",
    difficulty: "medium",
    question: "How do you handle collisions in a hash table using chaining?",
    options: ["Linear probing", "Quadratic probing", "Linked lists at each bucket", "Rehashing"],
    correctAnswer: "Linked lists at each bucket",
    explanation: "Chaining uses linked lists to store multiple elements that hash to the same bucket.",
    tags: ["hash-tables", "collision-resolution", "chaining"],
  },
  {
    id: "q017",
    topic: "heaps",
    difficulty: "medium",
    question: "What is the time complexity of building a heap from an unsorted array?",
    options: ["O(n log n)", "O(n)", "O(log n)", "O(n²)"],
    correctAnswer: "O(n)",
    explanation: "Building a heap bottom-up (heapify) takes linear time, not O(n log n).",
    tags: ["heaps", "heapify", "time-complexity"],
  },
  {
    id: "q018",
    topic: "strings",
    difficulty: "medium",
    question: "Which algorithm is most efficient for pattern matching in strings?",
    options: ["Brute force O(nm)", "KMP O(n + m)", "Boyer-Moore O(n/m) best case", "All are equally efficient"],
    correctAnswer: "KMP O(n + m)",
    explanation: "KMP algorithm guarantees O(n + m) time complexity for pattern matching.",
    tags: ["strings", "pattern-matching", "kmp"],
  },
  {
    id: "q019",
    topic: "bit-manipulation",
    difficulty: "medium",
    question: "How do you check if a number is a power of 2 using bit manipulation?",
    options: ["n & (n-1) == 0", "n | (n-1) == 0", "n ^ (n-1) == 0", "n + (n-1) == 0"],
    correctAnswer: "n & (n-1) == 0",
    explanation: "Powers of 2 have only one bit set, so n & (n-1) removes that bit, resulting in 0.",
    tags: ["bit-manipulation", "power-of-two", "bitwise-operations"],
  },
  {
    id: "q020",
    topic: "greedy",
    difficulty: "hard",
    question: "When is a greedy algorithm guaranteed to find the optimal solution?",
    options: [
      "Always",
      "Never",
      "When the problem has optimal substructure and greedy choice property",
      "Only for sorting problems",
    ],
    correctAnswer: "When the problem has optimal substructure and greedy choice property",
    explanation: "Greedy algorithms work optimally when local optimal choices lead to global optimum.",
    tags: ["greedy", "optimal-solution", "algorithm-design"],
  },
]

export const TOPIC_WEIGHTS = {
  arrays: 0.15,
  "linked-lists": 0.1,
  trees: 0.15,
  sorting: 0.1,
  "dynamic-programming": 0.15,
  recursion: 0.05,
  graphs: 0.15,
  "hash-tables": 0.05,
  heaps: 0.05,
  strings: 0.05,
  "bit-manipulation": 0.03,
  greedy: 0.02,
}

export const DIFFICULTY_POINTS = {
  easy: 1,
  medium: 2,
  hard: 3,
}
